# ARSVD_comparison

Implementation and evaluation of **Adaptive-Rank Singular Value Decomposition (ARSVD)** from research literature, compared against standard **truncated SVD** on U-Net weights for medical image segmentation.

This repository reproduces and extends the **ARSVD algorithm** proposed in research for low-rank compression, applying it to a deep learning segmentation model (U-Net) on the Brain Tumor dataset.  
The pipeline allows systematic comparison of **ARSVD**, **fixed-rank SVD**, and **original U-Net** in terms of accuracy, model size, and parameter efficiency.

---

## Key Features
- **Research replication:** Implements ARSVD as proposed in literature, allowing direct comparison with standard SVD truncation.
- **Full U-Net training and evaluation** on COCO-style medical segmentation dataset.
- **Adaptive-rank selection** using entropy thresholding.
- **Modular pipeline**:
  - Data ingestion (COCO) â†’ U-Net training â†’ ARSVD/SVD compression â†’ Evaluation.
- **Detailed metrics**:
  - Dice coefficient, IoU, and pixel accuracy.
  - Parameter count, model size, and compression %.
- **Colab-ready**: easily runs with GPU acceleration or on CPU.

---

## Research Context

**Adaptive-Rank SVD (ARSVD)** dynamically selects truncation rank using entropy of singular value distributions, unlike fixed-rank SVD.  
This yields a compressed representation that preserves most of the model energy while significantly reducing parameters.  

This project extends the original ARSVD formulation to convolutional layers in deep segmentation networks (U-Net), providing an empirical comparison on a medical dataset.

##  Dataset

This project uses the **Brain Tumor Image Dataset (Semantic Segmentation)** available on [Kaggle](https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-image-dataset-semantic-segmentation).

The dataset follows a COCO-style annotation format and contains:
- Train, validation, and test splits.
- Corresponding `_annotations.coco.json` files for segmentation masks.
- Brain tumor MRI images with pixel-level tumor annotations.

To use this dataset:
1. Download it from Kaggle:  
   [Brain Tumor Image Dataset (Semantic Segmentation)](https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-image-dataset-semantic-segmentation)
2. Extract it so that your folder structure looks like:
data/
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ _annotations.coco.json
â”‚ â””â”€â”€ *.jpg
â”œâ”€â”€ valid/
â”‚ â”œâ”€â”€ _annotations.coco.json
â”‚ â””â”€â”€ *.jpg
â””â”€â”€ test/
â”œâ”€â”€ _annotations.coco.json
â””â”€â”€ *.jpg
---

3. Set `--data_root` to point to this directory when running:
# bash
python run_pipeline.py --data_root ./data --device cuda


## ğŸ“ Repository structure

ARSVD_comparison/
â”œâ”€â”€ data/ 
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ unet.py 
â”‚ â”œâ”€â”€ compression.py # ARSVD + SVD implementations
â”‚ â”œâ”€â”€ evaluation.py # Metrics and comparison utilities
â”‚ â””â”€â”€ base.py # Abstract model definitions
â”œâ”€â”€ steps/ # Pipeline steps (ingest, train, evaluate)
â”œâ”€â”€ pipelines/train_pipeline.py
â”œâ”€â”€ run_pipeline.py # Orchestrates full pipeline (train â†’ compress â†’ evaluate)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Installation

# bash
python -m venv my_env
source my_env/bin/activate
pip install -r requirements.txt


## âš™ï¸ Installation
python run_pipeline.py \
  --data_root /absolute/path/to/data_root \
  --out_dir ./artifacts_cpu \
  --device cpu \
  --batch_size 4 \
  --epochs 3

## Train + compare with GPU (Colab or CUDA)
python run_pipeline.py \
  --data_root /path/to/data_root \
  --out_dir ./artifacts_gpu \
  --device cuda \
  --epochs 5

## Sweep multiple ranks/taus
python run_pipeline.py \
  --data_root /path/to/data_root \
  --out_dir ./experiments/run1 \
  --device cuda \
  --epochs 5 \
  --svd_ranks "16,32,64" \
  --arsvd_taus "0.85,0.9,0.95"
